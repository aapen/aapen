* Quality of Life
** DONE Make codespaces work
- [X] Question: can the codespaces config require an aarch64 container?
        Answer: no it cannot
- [X] Set up container with tools: zig (pinned to a dev snapshot), qemu, gdb-multiarch
** DONE Make devpod.sh work
** HOLD Get devpod.sh to work on Mike's personal machine.                                                       :HOLD:
There seems to be a docker network problem. Devpod.sh works great on the macOS laptop.
** DONE Discuss device tree & DTBs with Russ
Advantages: 
- Common, open-source mechanism to describe per-board variations in e.g., memory locations of GPIO, UART, mailbox, etc.
- OpenFirmware and Devicetree.org have tons of .dts (source files) available, including all the devices we're interested in.
Disadvantages:
- Variability brings complexity. But so does a generalization / abstraction layer. Will we get enough boost from .dtbs to be worth the added complexity of supporting them?
Unknowns: 
- How would we integrate this with our toolchain? We're already grabbing the .dtbs, but we don't have a compiler to create them from source. Nor do we have a runtime library for parsing them. Do we need to make a Zig module for reading the binary format? Do we need to make a Zig compiler to emit the binary format?

Alternative: Use the .dtb for our reference, but don't parse it in code at boot
Advantages:
- Simplicity. Dev speed (at first).

Disadvantages:
- Difficult to support a plethora of devices.

Maybe we use the dtbs as references for our own use rather than writing code to parse them at boot time.
*** Notes and references
https://github.com/devicetree-org/devicetree-specification

Linux device tree compiler: https://git.kernel.org/pub/scm/utils/dtc/dtc.git
- Can be installed on ubuntu with ~apt install device-tree-compiler~
- The compiler ~dtc~ can also decompile the binaries: ~dtc -I dtb -O dts bcm2711-rpi-4-b.dtb~ is _very_ interesting!

The low-level boot code that runs on the GPU (start*.elf) seems to
pull the device tree binary into memory for us. By the time ~_start~ is
called, register X0 contains the address of the device tree data. (It
starts with the magic word ~0xd00dfeed~.)

** DONE Figure out how to have the system under test exit QEMU
This will be useful for writing tests
*** Notes & References
The technique needed is "semihosting". This allows certain traps to
act as a syscall to communicate with the emulator.

We can use this to tell QEMU to exit with some particular status code.

It is also possible to use this as another text channel, though we
probably don't want to use it that way. That channel and any messages
sent on it would never be visible when using real hardware.

According to
https://www.qemu.org/docs/master/about/emulation.html#semihosting, the
instruction used differs per ARM processor. Our target devices all use
Cortex-A series processors in 64-bit mode, so we use ~HLT #0xF000~ to
invoke the semihosting interface.

Before executing the HLT, we put the "operation number" in W0 and a
single parameter number in X1. After the HLT, X0 holds the return code
from the semihosted call, although we mostly want to exit QEMU so
return is not a concern.

Per https://www.qemu.org/docs/master/about/emulation.html#semihosting,
we can use ~SYS_EXIT~ (0x18) as the operation number. The parameter in
X1 points to a 2 a struct of 2 u64's which indicates /why/ the exit is
taken. We will use ~ADP_Stopped_ApplicationExit~ (0x20026) for
field 1. Field 2 will have the exit status code we want to
signal. QEMU will then use that status code as it's own exit code, so
the parent process can see what the kernel wanted to indicate.

QEMU docs on semihosting: https://www.qemu.org/docs/master/about/emulation.html#semihosting

ARM docs on the semihosting interface: https://github.com/ARM-software/abi-aa/blob/main/semihosting/semihosting.rst
** DONE Use the old chainboot kernel & jtag boot from https://github.com/rust-embedded/rust-raspberrypi-OS-tutorials
Stage 1 on the SD card
Stage 2 (the chainboot) downloaded automatically by minipush.rb
Stage 3 (the real kernel) loaded via gdb (connected via openocd)
** HOLD Use Python and the Python binding to libfdt to parse .dtb files?                                        :HOLD:
* Milestone: Run a kernel
** DONE Perform "Hello world" as RPi3 under QEMU
** DONE Perform "Hello world" on RPi3 hardware*
** DONE Prepare for "real" operating mode
- [X] Set up interrupt handler tables, point everything to a "panic" that dumps state on UART
- [X] Transition from EL2 to EL1
<<<<<<< HEAD
- [ ] copy kernel to high memory
=======
>>>>>>> 2c172d5 (Some notes to self)
- [X] Set up translation tables
- [X] Reserve the device pages, mark them in TT properly
- [X] Mark kernel text pages as RX, kernel data (GOT, stack, BSS) as RW/NX
** TODO Perform "Hello world" on RPi4 hardware
* Milestone: Interact
** DONE Read from UART on RPi3 under QEMU
Read and echo characters.
Polling is fine.
This will actually be the host machine's keyboard in a terminal, proxied to the PL011 UART in the emulated device.
** DONE Make the GPIO pins available for blinkenlights, or even useful stuff. They should be super-easy to use from Forth
- [X] Define a ziggish API (@russ)
- [X] Make the register dance support that API (@mike)
- [ ] Define forthish words (@russ) for pin operations
** DONE Finish declarations of other GPIO pins (besides 14 & 15 which are needed for the UART)
** DONE Read from UART on RPi3
- [X] Read and echo characters.
- [X] Use UART interrupts, don't spinloop
** TODO Read from UART on RPi4
** TODO Read from USB keyboard input under QEMU
** TODO Read from USB on RPi3 hardware
** TODO Read from USB on RPi4 hardware
** DONE Switch to using interrupts instead of polling
* Milestone: Get Ziggy
** DONE Replace C stubs with equivalent Zig
** DONE Use Zig cross-compilation instead of crosstools
* Milestone: Monitor it
** DONE Read commands from input
Command line looks like:

~! 00000000 ffffffff~ - write a 32 bit words at the address
~? 00000000 xx~ - display xx words of memory starting at the address

All other starting characters are ignored.

* Milestone: Show the World
** TODO Read from USB keyboard on RPi 400
** DONE Create interface for "mailbox" from CPU to GPU
** TODO Enable DMA for video blitting
** DONE Create a "character ROM" for displaying text
** TODO Initialize video system on RPi 400
** TODO Clear screen on RPi 400
** DONE Display a text cursor
** DONE Write characters to the screen
** DONE Echo typed characters to the screen
** DONE Make panics write to the screen
* Milestone: Set Forth
** NEXT Read basic words
Stack ops:
- [X] swap
- [X] dup
- [X] drop
- [X] rot
- [X] over
- [X] 2swap
- [X] 2dup
- [X] 2drop
- [X] 2rot
- [X] 2over
Arithmetic:
- [X] +
- [X] -
- [ ] *
- [ ] /
- [ ] %
Input/Output:
- [X] hello
- [X] cr
- [X] emit
- [X] cls
- [X] key
- [X] key?
System info:
- [X] ?
- [X] ??
- [X] stack
- [X] ip
- [X] info
- [X] value-size
Memory:
- [X] !i
- [X] @i

* Other references
** Understanding the ARM ecosystem
https://www.youtube.com/watch?v=NNol7fRGo2E
** Debugging in hardware
*** All-in-one option
Kicad files: https://github.com/chickadee-tech/pi-developer
Sold direct: https://oshpark.com/shared_projects/fBq76nP9

BOM not included... needs JTAG header, GPIO header, 4 LEDs, some resistors (330 Ohm? 4.7K? who knows.)
** MMU
Video on address translation & the interaction of granule size with L0-L3 tables: https://www.youtube.com/watch?v=yTKpniRaEoI
** GPU interface
Communication from CPU to GPU is via a "mailbox" interface.

Many of the mailbox commands ("tags") require addresses. These must be translated to the GPU's view of address space, as described in section 1.2 of "Broadcom BCM2837 Peripheral Reference" (titled "Address Map") and section 1.2 of "Broadcom BCM2711 ARM Peripherals" (also titled "Address Map").
*** References
- [[https://github.com/hackerspace/rpi-linux/blob/lr-raspberry-pi-new-mailbox/drivers/mailbox/bcm2835-mailbox.c][bcm2835-ipc.c]] by Lubomir Rintel and Broadcom
- [[https://github.com/raspberrypi/firmware/wiki/Mailbox-property-interface][Raspberry Pi Firmware wiki]]
** USB interface
Getting USB up and running is going to be a big job.
*** TODO Define structure of xHCI registers
*** TODO Initialize the xHCI controller itself
*** TODO Create kernel structures to represent the devices (Hardware abstraction layer)
*** TODO Set up doorbell interface from kernel to xHCI
*** TODO Set up interrupt handler from xHCI to kernel
*** TODO Enumerate USB devices
*** TODO Initialize / setup / assign slot for one USB device
*** TODO Define a keyboard device class interface
*** TODO Expose keyboard input to kernel as high-level key events
*** Reference
https://www.intel.com/content/dam/www/public/us/en/documents/technical-specifications/extensible-host-controler-interface-usb-xhci.pdf

* Open Questions
** How should we set up a default allocator for zig?
*** Notes and references
std.mem.Allocator uses a struct called "vtable" to create an interface which all allocators implement. ~vtable~ contains function pointers. References to std.mem.Allocator.VTable are littered throughout the standard library.

Whenever looking up the default allocator, stdlib functions first check for ~root.os.page_allocator~. If it is present, it is used. ~root~ is an alias for the top-level struct of application code. This allows us to provide the default implementation.

Approach:
1. At top level, create a member named "os". It will be a struct with (initially) one member "page_allocator".
2. That page allocator will be supplied by our OS. The OS will construct it with start of heap and end of heap as provided by the linker.
3. Initial implementation will be naive: use up remaining free space until it runs out, then return out of memory forever.

** What is the right "ziggish" way to inject the BSP into the architecture?
Right now the architecture module @import's the BSP. This seems backwards. The evidence is in ~build.zig~ where we see a dependency from the architecture module (which is meant to be specific to the _CPU_ architecture) to the BSP module (which is the board the CPU is in). This seems logically backwards to me. Moreover, it cements the choice of board as a comptime decision and I still have the hope of making it a boottime decision.
** Should we replace the jtag boot & chainloader with our own?
** Trying to initialize the framebuffer on real hardware.
It's not working the same way as in the emulator.

Mailbox request:
|   Word |   Value | Meaning                              |
|--------+---------+--------------------------------------|
|      0 |    0xf8 | total size of message (248) in bytes |
|      1 |       0 | this is a request                    |
|     -- |      -- | --                                   |
|      2 | 0x48003 | set physical size                    |
|      3 |     0x8 | value buffer size in bytes           |
|      4 |     0x8 | request size in bytes                |
|      5 |   0x400 | x resolution 1024 pixels             |
|      6 |   0x300 | y resolution 768 pixels              |
|     -- |      -- | --                                   |
|  7..11 |         | set virtual resolution               |
| 12..15 |         | set pixel depth                      |
|     -- |      -- | --                                   |
|     16 | 0x40001 | allocate framebuffer                 |
|     17 |     0x8 | value buffer size in bytes           |
|     18 |     0x4 | request size in bytes                |
|     19 |    0x10 | alignment in bytes                   |
|     20 |     0x0 | undefined                            |

Mailbox response:
|   Word |      Value | Meaning                                                  |
|--------+------------+----------------------------------------------------------|
|      0 |       0xf8 | total size of message (248) in bytes                     |
|      1 | 0x80000001 | error response                                           |
|     -- |         -- | --                                                       |
|      2 |    0x48003 | set physical size                                        |
|      3 |        0x8 | value buffer size in bytes                               |
|      4 | 0x80000008 | bit 31 indicates a response, or-ed with the response len |
|      5 |      0x400 | requested x resolution                                   |
|      6 |      0x300 | requested y resolution                                   |
|     -- |         -- | --                                                       |
|  7..11 |            | set virtual resolution                                   |
| 12..15 |            | set pixel depth                                          |
|     -- |         -- | --                                                       |
|     16 |    0x40001 | allocate framebuffer                                     |
|     17 |        0x8 | value buffer size in bytes                               |
|     18 | 0x80000008 | bit 31 indicates a response, or-ed with the response len |
|     19 | 0xfeb3a000 | address of frame buffer?                                 |
|     20 |    0xc0000 | size of frame buffer?                                    |





* Closed Questions
** DONE Should we use device tree? If so, how?
   Answer: Not yet. We need to keep things as simple as possible while we get up and running. Rather than doing a bunch of things dynamically at boot based on hardware discovery, we want to get a single model working first. That means we accept that some things (such as MMIO address) will be built in at compile time.
** DONE Changing a .zig file in a module doesn't trigger recompilation. Why not?
The Makefile didn't even invoke ~zig build~ because there was no rule that depended on the source files themselves.
** DONE Discuss zig weirdness with Russ
It was due to using ~callconv(.Naked)~ on ~kernel_init~. Zig didn't generate a function prelude (which is what "naked" means) but it also assumed there was room on the stack for the variables. Oddly some of the variable accesses were negative offsets from the frame pointer while others were positive offsets from the stack pointer. Since the FP and SP were not where the compiler expected them to be, the variables were all mixed up.
*** With -DOptimize=ReleaseSafe
We get a data fault on the instruction ~str     w11, [x9]~ (compiled at 0x8126c, w11 = 0x24000, x9 = 0xff004)
- x9 points into memory that the linker should have marked as kernel text and the MMU has marked as kernel code (and therefore read-only)
- It's coming from the GPIO code, in the code compiled from
#+begin_src zig
    // Configure GPIO pins for serial I/O
    gpio_function_select_1.modify(.{
        .fsel14 = .alt0,
        .fsel15 = .alt0,
    });
#+end_src

This is supposed to do a raw-read, modify bitfields, and raw-write back to the register address.

Under -DOptimize=ReleaseSafe, that register address is in ~x9~ and is 0xff004 instead of 0x3f000000 + 0x200000 + 0x04

Answer:

The generated assembly code sets up registers x19 and x20 with the GPIO base address, which is later used with an integer index to point to one GPIO register or another. However, the compiler emits code that sets up those registers /before/ it emits the calls to ~pagetable_init()~ and ~mmu_on()~. Those functions (generated by arm64-pgtable-tool) absolutely don't conform to the ARM64 Procedure Calling Standard... they walk all over registers x19 and x20 (and x21 and x22). The solution is to make ~pagetable_init()~ and ~mmu_on()~ conform to the standard which designates x19 through x28 as callee-saved registers.

Followup: That worked.

** Do we need to worry about endianness, or can we just go with whatever RPi uses as a default?
   Answer: Best to stick with the default at boot.
** Speaking of which, what _does_ it use as a default?
   Answer: Big endian
** How does the RPi 400 keyboard work? Is it just USB connected internally?
   Answer: According to https://www.40percent.club/2020/11/raspberry-pi-400-keyboard-controller.html, the Pi 400 keyboard goes through a custom microcontroller (Holtek HT45R0072) which then goes into one of the 4 USB ports on the builtin controller. So it presents as a USB HID.
